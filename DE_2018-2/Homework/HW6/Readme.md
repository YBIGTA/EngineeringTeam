## 과제 6
<br>

### Test Data
  - 실습 데이터 중 'madrid_2017.csv'
  - (구글 드라이브의 1.Session/20180811/ 에 업로드)
<br>

### 과제 개요
  - 이 과제의 목표는 실습 때 이용해본 HiveQL으로 여러가지 쿼리문을 작성해봄으로써 이에 익숙해지는 데 있습니다.
  - 테이블을 생성하고, 데이터를 업로드하고, 집계 함수를 사용해서 데이터를 검색해봅니다.
<br>
   
### 과제 내용
1. 하이브 실행

2. 테이블 생성
    - air_quality라는 이름으로 테이블을 만든다
    - 순서대로 integer타입의 Year, Month, Time이라는 column과 double 타입의 CO, NO라는 column, 그리고 integer 타입의 station이라는 column을 갖는다.
    - integer 타입의 CollectYear라는 키로 파티션한다.
    - 필드는 콤마(,)로 구분하고 각 행은 개행문자(\n)으로 구분
    - TEXTFILE 형태로 저장
    - 힌트: 실습때 생성한 테이블과 동일

3. 데이터 업로드
    - madrid_2017.csv라는 파일을 air_quality 테이블에 업로드
    - (파티션키) CollectYear이 2017인 데이터에 대해 수행
    - 힌트: 실습과 동일

4. 연산
    
    **[4-1]** 2017년도의 데이터 중 NO의 값이 10을 넘는 행의 개수를 구하시오.

    **[4-2]** CollectYear값이 2017이고 CO가 0보다 큰 행을 대상으로, 연도와 월별 CO의 평균과 NO의 평균을 구하시오. 
    이 때, CO의 평균을 기준으로 내림차순 정렬하시오.
    (CO 평균의 컬럼 이름 : avg_CO // NO 평균의 컬럼 이름 : avg_NO)
    
    **[4-3]** 
<br>

### 구현 가이드
  - 세션 자료 (특히 실습부분) 참고
<br>

### 실행 가이드
  - EC2 에서 하둡과 하이브를 실행시킨다.
  - 과제와 함께 첨부된 예제 데이터 파일을 hdfs 의 원하는 경로에 업로드한다.
  - 쉘에서 실습을 수행한다.    
<br>

### 제출 파일
  - 각 항목별 실행 결과 화면을 캡처한 이미지

